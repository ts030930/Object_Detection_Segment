# Why YOLOv3?

YOLOv3 (You Only Look Once version 3) is one of the most popular real-time object detection algorithms.  
It balances **speed** and **accuracy**, making it highly suitable for applications like traffic sign detection.

---

### ğŸ”¹ Key Features of YOLOv3
1. **Multi-scale prediction**  
   - Uses 3 different scales for bounding box prediction (small, medium, large objects).  
   - Improves detection of small objects like traffic signs.  

2. **Darknet-53 backbone**  
   - A powerful CNN with 53 convolutional layers.  
   - Combines **residual connections** (like ResNet) for better gradient flow and feature extraction.  

3. **Anchor boxes**  
   - Utilizes predefined anchor boxes similar to Faster R-CNN and SSD.  
   - Improves localization of objects with varying aspect ratios.  

4. **Logistic regression for objectness**  
   - Each bounding box predicts objectness score (how likely the box contains an object).  
   - Reduces false positives.  

5. **Class prediction as independent logistic classifiers**  
   - Unlike softmax, YOLOv3 uses multiple independent logistic classifiers.  
   - Helps in detecting overlapping classes and multi-label cases.  

6. **Speed and efficiency**  
   - Capable of real-time detection (30â€“45 FPS on GPU).  
   - Lightweight compared to two-stage detectors like Faster R-CNN.  

---

### ğŸ”¹ YOLOv3ì˜ ì£¼ìš” íŠ¹ì§• (í•œêµ­ì–´)
1. **ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì˜ˆì¸¡**  
   - ì„¸ ê°€ì§€ ë‹¤ë¥¸ í¬ê¸°ì˜ íŠ¹ì„± ë§µì—ì„œ ì˜ˆì¸¡ ìˆ˜í–‰ (ì‘ì€ ë¬¼ì²´, ì¤‘ê°„ í¬ê¸°, í° ë¬¼ì²´).  
   - êµí†µ í‘œì§€íŒ ê°™ì€ ì‘ì€ ê°ì²´ íƒì§€ ì„±ëŠ¥ í–¥ìƒ.  

2. **Darknet-53 ë°±ë³¸**  
   - 53ê°œ í•©ì„±ê³± ê³„ì¸µìœ¼ë¡œ êµ¬ì„±ëœ ê°•ë ¥í•œ CNN êµ¬ì¡°.  
   - ResNetì²˜ëŸ¼ **ì”ì°¨ ì—°ê²°(Residual Connection)** ì„ í™œìš©í•´ í•™ìŠµ ì•ˆì •ì„±ê³¼ í‘œí˜„ë ¥ ê°•í™”.  

3. **ì•µì»¤ ë°•ìŠ¤(Anchor Box) ì‚¬ìš©**  
   - ë¯¸ë¦¬ ì •ì˜ëœ ì—¬ëŸ¬ ë¹„ìœ¨/í¬ê¸°ì˜ ë°•ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡.  
   - ë‹¤ì–‘í•œ ë¹„ìœ¨ì˜ ë¬¼ì²´ë¥¼ ë” ì •í™•íˆ íƒì§€ ê°€ëŠ¥.  

4. **ë¡œì§€ìŠ¤í‹± íšŒê·€ ê¸°ë°˜ Objectness ì ìˆ˜**  
   - ê° ë°•ìŠ¤ë§ˆë‹¤ ê°ì²´ê°€ ì¡´ì¬í•  í™•ë¥ (Objectness) ì˜ˆì¸¡.  
   - ì˜ëª»ëœ íƒì§€(ì˜¤íƒ)ë¥¼ ì¤„ì„.  

5. **ë…ë¦½ì ì¸ ë¡œì§€ìŠ¤í‹± ë¶„ë¥˜ê¸° ê¸°ë°˜ í´ë˜ìŠ¤ ì˜ˆì¸¡**  
   - Softmax ëŒ€ì‹  ì—¬ëŸ¬ ë…ë¦½ ë¡œì§€ìŠ¤í‹± ë¶„ë¥˜ê¸°ë¥¼ ì‚¬ìš©.  
   - ì¤‘ì²©ë˜ê±°ë‚˜ ë‹¤ì¤‘ í´ë˜ìŠ¤ ìƒí™©ì—ì„œë„ ì˜ ì‘ë™.  

6. **ì†ë„ì™€ íš¨ìœ¨ì„±**  
   - GPU í™˜ê²½ì—ì„œ ì‹¤ì‹œê°„ íƒì§€ ê°€ëŠ¥ (ì•½ 30~45 FPS).  
   - Faster R-CNN ê°™ì€ 2ë‹¨ê³„ ê²€ì¶œê¸°ë³´ë‹¤ ê°€ë³ê³  ë¹ ë¦„.  

---

ê²°ë¡ ì ìœ¼ë¡œ, YOLOv3ëŠ” **ì‹¤ì‹œê°„ì„±, ì •í™•ë„, ì‘ì€ ê°ì²´ íƒì§€ ì„±ëŠ¥**ì„ ë™ì‹œì— ê°–ì¶˜ ëª¨ë¸ì´ê¸° ë•Œë¬¸ì—  
êµí†µ í‘œì§€íŒê³¼ ê°™ì€ ì‘ê³  í° ì—¬ëŸ¬ í¬ê¸°ì˜ ê°ì²´ íƒì§€ê°€ ì¤‘ìš”í•œ **Traffic Sign Detection Project**ì— ì‚¬ìš©í•˜ê¸°ë¡œ í–ˆë‹¤.



## Interpreting the output

YOLO V3ì—ì„œëŠ” ì¶”ì¶œëœ **íŠ¹ì§• ë§µ(Feature Map)** ì„ ì´ìš©í•˜ì—¬ 1x1 Convë¥¼ ì ìš©í•´ í”½ì…€ í•˜ë‚˜í•˜ë‚˜ë§ˆë‹¤
**Cell**ë‹¨ìœ„ë¡œ Objectë¥¼ íƒì§€ í•  ìˆ˜ ìˆê²Œ í–ˆëŠ”ë°, 
GridÂ size=SÃ—S, BoundingÂ boxesÂ perÂ cell=N,C = í´ë˜ìŠ¤ ê°œìˆ˜ ì¼ë•Œ
ê° ë°”ìš´ë”© ë°•ìŠ¤ê°€ ì˜ˆì¸¡í•˜ëŠ” ê°’ì˜ ì°¨ì› = D=(4+1+C)ì´ê³ ,
<img width="600" height="819" alt="image" src="https://github.com/user-attachments/assets/e9ec8026-e223-472b-a36a-3bad4c954e02" />

ìµœì¢… Output í…ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì•„ì§„ë‹¤.


## Anchor Box

YOLOV3ì—ëŠ” 3ê°œì˜ anchor Boxê°€ ì¡´ì¬í•œë‹¤.
ê·¸ëŸ¬ë¯€ë¡œ ê° Cellë‹¹ 3ê°œì˜ Boxë¥¼ ê°€ì§€ëŠ” ê²ƒì´ë‹¤.
ë˜ YOLO ëª¨ë¸ì€ ê° Cellë§ˆë‹¤ **ì±…ì„** Boxë¥¼ ê°€ì§€ëŠ”ë°, ì´ë–„ GTì™€ IOUê°€ ê°€ì¥ ë†’ì€ BOXê°€ ì±…ì„ Boxë¡œ ì„ ì •ë˜ì–´ì„œ í•™ìŠµì´ ì§„í–‰ëœë‹¤.

<img width="655" height="419" alt="image" src="https://github.com/user-attachments/assets/578f7f1c-43cc-4ff1-98a7-a0ebf8a43d8b" />

<img width="369" height="272" alt="image" src="https://github.com/user-attachments/assets/36ba1109-9fa8-424b-908a-b002499cea94" />

---


### Objective Score & Class Confidences
<img width="600" height="819" alt="image" src="https://github.com/user-attachments/assets/e9ec8026-e223-472b-a36a-3bad4c954e02" />

-**Objective Score**
Objectness ScoreëŠ” ì˜ˆì¸¡ëœ ë°”ìš´ë”© ë°•ìŠ¤ ì•ˆì— **ì‹¤ì œë¡œ ê°ì²´ê°€ ì¡´ì¬í•  í™•ë¥ **ì„ ì˜ë¯¸í•œë‹¤.  
  - ê°ì²´ì™€ ê²¹ì¹˜ëŠ” ì…€ â†’ ê°’ì´ 1ì— ê°€ê¹Œì›€  
  - ê°ì²´ê°€ ì—†ëŠ” ë°°ê²½ ì…€ â†’ ê°’ì´ 0ì— ê°€ê¹Œì›€  
  ì´ ê°’ì€ í™•ë¥ ì²˜ëŸ¼ í•´ì„ë˜ë¯€ë¡œ **ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜(sigmoid)** ë¥¼ ê±°ì³ ì¶œë ¥ëœë‹¤.


-**Objective Score**
Objectness ScoreëŠ” ì˜ˆì¸¡ëœ ë°”ìš´ë”© ë°•ìŠ¤ ì•ˆì— **ì‹¤ì œë¡œ ê°ì²´ê°€ ì¡´ì¬í•  í™•ë¥ **ì„ ì˜ë¯¸í•œë‹¤.  
  - ê°ì²´ì™€ ê²¹ì¹˜ëŠ” ì…€ â†’ ê°’ì´ 1ì— ê°€ê¹Œì›€  
  - ê°ì²´ê°€ ì—†ëŠ” ë°°ê²½ ì…€ â†’ ê°’ì´ 0ì— ê°€ê¹Œì›€  
  ì´ ê°’ì€ í™•ë¥ ì²˜ëŸ¼ í•´ì„ë˜ë¯€ë¡œ **ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜(sigmoid)** ë¥¼ ê±°ì³ ì¶œë ¥ëœë‹¤.


-**Class Confidences**
Class ConfidenceëŠ” íƒì§€ëœ ê°ì²´ê°€ ê° í´ë˜ìŠ¤(ì˜ˆ: ê°œ, ê³ ì–‘ì´, ìë™ì°¨, ë°”ë‚˜ë‚˜ ë“±)ì— ì†í•  **í™•ë¥  ë¶„í¬**ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.  
  - YOLOv1, v2 â†’ Softmaxë¥¼ ì‚¬ìš©í•´ í´ë˜ìŠ¤ ì ìˆ˜ë¥¼ ì •ê·œí™”í•¨.  
  - YOLOv3 â†’ Softmax ëŒ€ì‹  **Sigmoid í•¨ìˆ˜**ë¥¼ ì‚¬ìš©.

ì´ë•Œ ì™œ Sigmoidë¥¼ ì‚¬ìš©í•˜ëƒë©´, Softmaxì˜ ê²½ìš°ì—ëŠ” ì „ì²´ í™•ë¥ ì˜ í•©ì´ 1ì´ë¼
ë©€í‹° í´ë˜ìŠ¤ì˜ˆì¸¡ì— ì•½ê°„ì˜ ì œì•½ì´ ìƒê¸°ê¸° ë–„ë¬¸ì— Sigmoidë¥¼ ì´ìš©í•˜ì—¬ ìœ ì—°í•œ êµ¬ì¡°ë¥¼ ì±„íƒí–ˆë‹¤ê³  í•œë‹¤.

---










## Feature Extracter (Darknet -53)

YOLOv3ëŠ” **Darknet-53**ì´ë¼ëŠ” ìƒˆë¡œìš´ Feature Extractor(ë°±ë³¸ ë„¤íŠ¸ì›Œí¬)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.  
ì´ ë„¤íŠ¸ì›Œí¬ëŠ” **Darknet-19**ì˜ íš¨ìœ¨ì„±ê³¼ **ResNet**ì˜ residual connection ì•„ì´ë””ì–´ë¥¼ ê²°í•©í•œ êµ¬ì¡°.


###  ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°
<img width="285" height="406" alt="image" src="https://github.com/user-attachments/assets/19bcc5f5-ad65-450b-b793-06180a2a6f26" />

- ì´ **53ê°œì˜ Convolutional Layer**ë¡œ êµ¬ì„±
- **3Ã—3, 1Ã—1 Convolution** ë°˜ë³µ
- **Residual Block**(Shortcut Connection) ë„ì… â†’ ê¹Šì€ ë„¤íŠ¸ì›Œí¬ì—ì„œë„ í•™ìŠµ ì•ˆì •í™”
- **Downsampling (stride=2 conv)** ìœ¼ë¡œ ì ì§„ì  Feature Map ì¶•ì†Œ




##  YOLOv3 Detection Layers

YOLOv3ëŠ” í•œ ì´ë¯¸ì§€ì—ì„œ **3ê°œì˜ Detection Layer**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë¡œ ë‹¤ë¥¸ í¬ê¸°ì˜ ë¬¼ì²´ë¥¼ íƒì§€í•©ë‹ˆë‹¤.  
ì´ë¥¼ ìœ„í•´ ì´ **9ê°œì˜ Anchor Box**ë¥¼ ì •ì˜í•˜ê³ , ê° Detection Layerì—ì„œ **3ê°œì”©(maskë¡œ ì§€ì •)** ì‚¬ìš©í•©ë‹ˆë‹¤.

---

###  Detection íë¦„
1. **Feature Extraction (Darknet-53)**
   - ì…ë ¥ ì´ë¯¸ì§€(ì˜ˆ: 416Ã—416)ë¥¼ Backbone(Darknet-53)ì— í†µê³¼ì‹œì¼œ  
     **3ê°œì˜ Feature Map**ì„ ì–»ìŒ: 52Ã—52, 26Ã—26, 13Ã—13

2. **Anchor Box ë¶„ë°° (mask ì‚¬ìš©)**
   - ì´ 9ê°œ anchor ì¤‘, ê° scaleì—ì„œ 3ê°œì”©ë§Œ ì‚¬ìš©  
   - `mask=0,1,2` â†’ ì‘ì€ anchor (10Ã—13, 16Ã—30, 33Ã—23) â†’ 52Ã—52 grid (ì‘ì€ ë¬¼ì²´)  
   - `mask=3,4,5` â†’ ì¤‘ê°„ anchor (30Ã—61, 62Ã—45, 59Ã—119) â†’ 26Ã—26 grid (ì¤‘ê°„ ë¬¼ì²´)  
   - `mask=6,7,8` â†’ í° anchor (116Ã—90, 156Ã—198, 373Ã—326) â†’ 13Ã—13 grid (í° ë¬¼ì²´)  

3. **Bounding Box ì˜ˆì¸¡**
   - ê° grid cellì´ **3ê°œì˜ anchor box**ë¥¼ ê¸°ì¤€ìœ¼ë¡œ (x, y, w, h), objectness, class probability ì˜ˆì¸¡  
   - ì˜ˆì¸¡ ê°œìˆ˜:
     - 52Ã—52Ã—3 = 8112  
     - 26Ã—26Ã—3 = 2028  
     - 13Ã—13Ã—3 = 507  
     - **ì´ 10647 box í›„ë³´**

4. **í›„ì²˜ë¦¬**
   - ë‚®ì€ objectness score ì œê±° (Thresholding)  
   - ê²¹ì¹˜ëŠ” ë°•ìŠ¤ ì œê±° (Non-Max Suppression, NMS)  
   - ìµœì¢…ì ìœ¼ë¡œ ì‹¤ì œ ë¬¼ì²´ ìˆ˜ë§Œí¼ì˜ Bounding Boxë§Œ ë‚¨ìŒ

---


ì´í›„ì—ëŠ” ê° íŒŒì¼ í´ë”ì˜ README.mdì— ìì„¸íˆ ì‘ì„±í–ˆë‹¤.




